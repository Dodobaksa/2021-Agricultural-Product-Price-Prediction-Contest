{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 농넷 전국도매시장 거래정보 데이터 API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import json\n",
    "import datetime\n",
    "import multiprocessing\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측일 기준 하루 전 날 도매 거래정보 데이터 추가\n",
    "today = datetime.datetime.today()\n",
    "yesterday = (today - datetime.timedelta(1)).strftime('%Y%m%d') \n",
    "url = 'https://www.nongnet.or.kr/api/whlslDstrQr.do?sdate=' # sdate = 날짜\n",
    "\n",
    "response = urllib.request.urlopen(url+yesterday).read()\n",
    "response = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data chk\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 파일 형태로 변환\n",
    "data=pd.DataFrame()\n",
    "for i in tqdm(range(1,0,-1)):\n",
    "    \n",
    "    today = datetime.datetime.today()\n",
    "    yesterday = (today - datetime.timedelta(i)).strftime('%Y%m%d') \n",
    "    url = 'https://www.nongnet.or.kr/api/whlslDstrQr.do?sdate=' # sdate = 날짜\n",
    "\n",
    "    response = urllib.request.urlopen(url+yesterday).read()\n",
    "    response = json.loads(response)\n",
    "    if not response['data']:\n",
    "        response['data']=[{'PUM_NM': 0,\n",
    "       'LV_NM': 0,\n",
    "       'TOT_AMT': 0,\n",
    "       'SAN_NM': 0,\n",
    "       'SALEDATE': yesterday ,\n",
    "       'CMP_NM': 0,\n",
    "       'DAN_NM': 0,\n",
    "       'WHSAL_NM':0,\n",
    "       'SIZE_NM': '.',\n",
    "       'COST': 0,\n",
    "       'POJ_NM': '상자',\n",
    "       'TOT_QTY': 0,\n",
    "       'QTY': 0,\n",
    "       'KIND_NM': 0,\n",
    "       'DANQ': 0}]\n",
    "\n",
    "\n",
    "    data = data.append(response['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data chk\n",
    "data['SALEDATE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pum = [\n",
    "        '배추', '무', '양파', '건고추','마늘',\n",
    "        '대파', '얼갈이배추', '양배추', '깻잎',\n",
    "        '시금치', '미나리', '당근',\n",
    "        '파프리카', '새송이', '팽이버섯', '토마토',\n",
    "    ]\n",
    "unique_kind = [\n",
    "        '청상추', '백다다기', '애호박', '캠벨얼리', '샤인마스캇'\n",
    "    ]\n",
    "\n",
    "kind_pum=unique_kind + unique_pum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pum=pd.DataFrame()\n",
    "for pum in unique_pum:\n",
    "    df_pum=df_pum.append(data[data['PUM_NM']==pum])\n",
    "\n",
    "for pum in unique_kind:\n",
    "    df_pum=df_pum.append(data[data['KIND_NM']==pum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pum=df_pum.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\n",
    "    'date':[]\n",
    "}\n",
    "\n",
    "for sub in unique_pum:\n",
    "    train_dict[f'{sub}_거래량(kg)'] = []\n",
    "    train_dict[f'{sub}_가격(원/kg)'] = []\n",
    "\n",
    "for sub in unique_kind:\n",
    "    train_dict[f'{sub}_거래량(kg)'] = []\n",
    "    train_dict[f'{sub}_가격(원/kg)'] = []\n",
    "\n",
    "\n",
    "days = sorted(data['SALEDATE'].unique())\n",
    "\n",
    "for day in tqdm(days):\n",
    "    train_dict['date'].append(day)\n",
    "    for sub in unique_pum:\n",
    "        # 날짜별, 품목별, 거래량이 0 이상인 행만 선택\n",
    "        c = data[(data['SALEDATE']==day) & (data['PUM_NM']==sub) & (data['TOT_QTY']>0)]\n",
    "        if c.shape[0] == 0:\n",
    "            train_dict[f'{sub}_거래량(kg)'].append(0)\n",
    "            train_dict[f'{sub}_가격(원/kg)'].append(0)\n",
    "        else:\n",
    "            tot_amt = c['TOT_AMT'].sum().astype(float)\n",
    "            tot_qty = c['TOT_QTY'].sum().astype(float)\n",
    "            mean_price = tot_amt/(tot_qty+1e-20)\n",
    "            train_dict[f'{sub}_거래량(kg)'].append(tot_qty)\n",
    "            train_dict[f'{sub}_가격(원/kg)'].append(mean_price)\n",
    "\n",
    "    for sub in unique_kind:\n",
    "        # 날짜별, 품종별, 거래량이 0 이상인 행만 선택\n",
    "        c = data[(data['SALEDATE']==day) & (data['KIND_NM']==sub) & (data['TOT_QTY']>0)]\n",
    "        if c.shape[0] == 0:\n",
    "            train_dict[f'{sub}_거래량(kg)'].append(0)\n",
    "            train_dict[f'{sub}_가격(원/kg)'].append(0)\n",
    "        else:\n",
    "            tot_amt = c['TOT_AMT'].sum().astype(float)\n",
    "            tot_qty = c['TOT_QTY'].sum().astype(float)\n",
    "            mean_price = round(tot_amt/(tot_qty+1e-20))\n",
    "            tot_qty = round(tot_qty, 1)\n",
    "            train_dict[f'{sub}_거래량(kg)'].append(tot_qty)\n",
    "            train_dict[f'{sub}_가격(원/kg)'].append(mean_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_private=pd.DataFrame(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_private['date'] = df_private.date.astype(str).str.replace('-','')\n",
    "df_private['date'] = pd.to_datetime(df_private.date, format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측일 기준 하루 전 날 21개 품목 거래 가격 데이터 chk\n",
    "df_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For modifying train, test dataset\n",
    "df_private.to_csv(\"new_common.csv\",index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating train & test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datum5 = pd.read_csv(\"C:/Users/KISLAB03/Desktop/2021-2/1234/data/train_update.csv\")\n",
    "datum5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datum6 = pd.read_csv(\"C:/Users/KISLAB03/Desktop/2021-2/1234/data/test_update.csv\")\n",
    "datum6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1003 = pd.read_csv(\"C:/Users/KISLAB03/Desktop/데이콘 영우형꺼/new_common.csv\")\n",
    "new1003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test dataset update\n",
    "# test dataset에 예측일 하루 전 날 거래 가격 데이터 추가\n",
    "new_1003 =pd.concat([datum6,new1003], axis=0)\n",
    "new_1003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test data는 29일치로 고정\n",
    "# 예측일 하루 전 날 데이터가 추가된 대신 test set 제일 첫 날 데이터를 제외한 test dataset 생성\n",
    "new_new_1003 = new_1003.iloc[1:,:]\n",
    "new_new_1003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_1003.to_csv(\"C:/Users/KISLAB03/Desktop/2021-2/1234/data/test_update.csv\", encoding=\"UTF-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 제일 첫 날 데이터를 train data로 이동하기 위해 별도 변수화\n",
    "con_1003 = new_1003.iloc[:1,:]\n",
    "con_1003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset update\n",
    "train_update= pd.concat([datum5,con_1003], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_update.to_csv(\"C:/Users/KISLAB03/Desktop/2021-2/1234/data/train_update.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 & 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import warnings\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add lag features & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(temp_df, pum, len_lag) :\n",
    "    # p_lag, q_lag 추가\n",
    "    for lag in range(1,len_lag+1) :\n",
    "      temp_df[f'p_lag_{lag}'] = -1\n",
    "      temp_df[f'q_lag_{lag}'] = -1\n",
    "      for index in range(lag, len(temp_df)) :\n",
    "        temp_df.loc[index, f'p_lag_{lag}'] = temp_df[f'{pum}_가격(원/kg)'][index-lag] #1일전, 2일전, ... 가격을 feature로 추가\n",
    "        temp_df.loc[index, f'q_lag_{lag}'] = temp_df[f'{pum}_거래량(kg)'][index-lag] #1일전, 2일전, ... 거래량을 feature로 추가\n",
    "\n",
    "    # month 추가\n",
    "    temp_df['date'] = pd.to_datetime(temp_df['date'])\n",
    "    temp_df['month'] = temp_df['date'].dt.month\n",
    "\n",
    "    # 예측 대상(1w,2w,4w) 추가\n",
    "    for week in ['1_week','2_week','4_week'] :\n",
    "      temp_df[week] = 0\n",
    "      n_week = int(week[0])\n",
    "      for index in range(len(temp_df)) :\n",
    "        try : temp_df[week][index] = temp_df[f'{pum}_가격(원/kg)'][index+7*n_week]\n",
    "        except : continue\n",
    "\n",
    "    # 불필요한 column 제거        \n",
    "    temp_df = temp_df.drop(['date',f'{pum}_거래량(kg)',f'{pum}_가격(원/kg)'], axis=1)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/data/train_update.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae(week_answer, week_submission):\n",
    "    answer = week_answer\n",
    "    target_idx = np.where(answer!=0)\n",
    "    true = answer[target_idx]\n",
    "    pred = week_submission[target_idx]\n",
    "    score = np.mean(np.abs(true-pred)/true)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def at_nmae(pred, y_true):\n",
    "    #y_true = dataset.get_label()\n",
    "    week_1_answer = y_true[0::3]\n",
    "    week_2_answer = y_true[1::3]\n",
    "    week_4_answer = y_true[2::3]\n",
    "    \n",
    "    week_1_submission = pred[0::3]\n",
    "    week_2_submission = pred[1::3]\n",
    "    week_4_submission = pred[2::3]\n",
    "    \n",
    "    score1 = nmae(week_1_answer, week_1_submission)\n",
    "    score2 = nmae(week_2_answer, week_2_submission)\n",
    "    score4 = nmae(week_4_answer, week_4_submission)\n",
    "    \n",
    "    score = (score1+score2+score4)/3\n",
    "    \n",
    "    return 'score', score, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pum = [\n",
    "    '배추', '무', '양파', '건고추','마늘',\n",
    "    '대파', '얼갈이배추', '양배추', '깻잎',\n",
    "    '시금치', '미나리', '당근',\n",
    "    '파프리카', '새송이', '팽이버섯', '토마토',\n",
    "]\n",
    "\n",
    "unique_kind = [\n",
    "    '청상추', '백다다기', '애호박', '캠벨얼리', '샤인마스캇'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble(XGBoost, AdaBoost, LGBM, RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "model_dict2 = {}\n",
    "model_dict3 = {}\n",
    "model_dict4 = {}\n",
    "split = 28 #validation\n",
    "\n",
    "for pum in tqdm(unique_pum + unique_kind):\n",
    "    # 품목 품종별 전처리\n",
    "    temp_df = train[['date',f'{pum}_거래량(kg)', f'{pum}_가격(원/kg)']]\n",
    "    temp_df = preprocessing(temp_df, pum, len_lag=28)\n",
    "    \n",
    "    # 주차별(1,2,4w) 학습\n",
    "    for week_num in [1,2,4] :\n",
    "        x = temp_df[temp_df[f'{week_num}_week']>0].iloc[:,:-3]\n",
    "        y = temp_df[temp_df[f'{week_num}_week']>0][f'{week_num}_week']\n",
    "        \n",
    "        #train, test split\n",
    "        x_train = x[:-split]\n",
    "        y_train = y[:-split]\n",
    "        x_valid = x[-split:]\n",
    "        y_valid = y[-split:]\n",
    "\n",
    "# 모델학습 및 그리드서치\n",
    "\n",
    "        model1 = XGBRegressor()\n",
    "        p = {'max_depth' : [3,4,5,6] , 'n_estimators': [12,24,32], 'learning_rate':[0.01, 0.1], 'gamma': [0.5, 1, 2], 'random_state':[2021]}\n",
    "        gcv = GridSearchCV(model1, param_grid=p, cv=5,  n_jobs=-1)\n",
    "        gcv.fit(x_train, y_train)\n",
    "        model2 = XGBRegressor(max_depth=gcv.best_params_['max_depth'], learning_rate=gcv.best_params_['learning_rate'],\n",
    "                             n_estimators = gcv.best_params_['n_estimators'], gamma=gcv.best_params_['gamma'])\n",
    "        \n",
    "\n",
    "        \n",
    "        model3 = AdaBoostRegressor()\n",
    "        p2 = {\n",
    "            'learning_rate': [0.1, 0.03],\n",
    "            'n_estimators': [50, 100, 200]\n",
    "        }\n",
    "        gcv2 = GridSearchCV(model3, param_grid=p2, cv=5,  n_jobs=-1)\n",
    "        gcv2.fit(x_train,y_train)\n",
    "        model4 = AdaBoostRegressor(n_estimators=gcv2.best_params_['n_estimators'], learning_rate=gcv2.best_params_['learning_rate'])\n",
    "        \n",
    "        \n",
    "        model5 = LGBMRegressor()\n",
    "        p3 = {\n",
    "            'num_leaves': [7, 14, 21],\n",
    "            'learning_rate': [0.1, 0.03],\n",
    "            'max_depth': [3, 5, 10],\n",
    "            'n_estimators': [50, 100, 200]\n",
    "        }\n",
    "        gcv3 = GridSearchCV(model5, param_grid=p3, cv=5,  n_jobs=-1)\n",
    "        gcv3.fit(x_train,y_train)\n",
    "        model6 = LGBMRegressor(learning_rate=gcv3.best_params_['learning_rate'],n_estimators=gcv3.best_params_['n_estimators'],\n",
    "                              num_leaves = gcv3.best_params_['num_leaves'], max_depth=gcv3.best_params_['max_depth'])\n",
    "        \n",
    "        \n",
    "        model7 = RandomForestRegressor()\n",
    "        p4 = {'n_estimators': [50,60,70],\n",
    "            'max_depth': [10,15,20],\n",
    "            'max_leaf_nodes':[50,100,200],\n",
    "            'max_features':['auto','sqrt','log2']}\n",
    "        gcv4 = GridSearchCV(model7, param_grid=p4, cv=5,  n_jobs=-1)\n",
    "        gcv4.fit(x_train,y_train)\n",
    "        model8 = RandomForestRegressor(n_estimators=gcv4.best_params_['n_estimators'],max_depth=gcv4.best_params_['max_depth'],\n",
    "                                     max_leaf_nodes=gcv4.best_params_['max_leaf_nodes'],max_features=gcv4.best_params_['max_features'] )\n",
    "        \n",
    "        \n",
    "        model_dict[f'{pum}_model_{week_num}'] = model2.fit(x_train, y_train)\n",
    "        model_dict2[f'{pum}_model_{week_num}'] = model4.fit(x_train, y_train)\n",
    "        model_dict3[f'{pum}_model_{week_num}'] = model6.fit(x_train, y_train)\n",
    "        model_dict4[f'{pum}_model_{week_num}'] = model8.fit(x_train, y_train)\n",
    "        \n",
    "        pred1 = model_dict[f'{pum}_model_{week_num}'].predict(x_valid)\n",
    "        pred2 = model_dict2[f'{pum}_model_{week_num}'].predict(x_valid)\n",
    "        pred3 = model_dict3[f'{pum}_model_{week_num}'].predict(x_valid)\n",
    "        pred4 = model_dict4[f'{pum}_model_{week_num}'].predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습이 잘 되었는지 chk\n",
    "pred2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"C:/Users/KISLAB03/Desktop/2021-2/1234/sample_submission.csv\")\n",
    "public_date_list = submission[submission['예측대상일자'].str.contains('2021')]['예측대상일자'].str.split('+').str[0].unique()\n",
    "# ['2021-09-28', ...]\n",
    "\n",
    "date = public_date_list[37] # 10/08기준 [10]에서 1씩 늘려가기 ex.10/09 > [11], 10월은 해당 날짜 +2\n",
    "\n",
    "test = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/data/test_update.csv')\n",
    "\n",
    "for pum in unique_pum + unique_kind:\n",
    "# 예측기준일에 대해 전처리\n",
    "    temp_test = pd.DataFrame([{'date' : date}]) #예측기준일\n",
    "    alldata = pd.concat([test, temp_test], sort=False).reset_index(drop=True)\n",
    "    alldata = alldata[['date', f'{pum}_거래량(kg)', f'{pum}_가격(원/kg)']].fillna(0)\n",
    "    alldata = alldata.iloc[-29:].reset_index(drop=True)\n",
    "    alldata = preprocessing(alldata, pum, len_lag=28)\n",
    "    temp_test = alldata.iloc[-1].astype(float)\n",
    "# 개별 모델을 활용하여 1,2,4주 후 가격 예측\n",
    "    for week_num in [1,2,4] :\n",
    "        temp_model = model_dict[f'{pum}_model_{week_num}']\n",
    "        result = temp_model.predict(temp_test[:-3].values.reshape(1, -1))\n",
    "        condition = (submission['예측대상일자']==f'{date}+{week_num}week')\n",
    "        idx = submission[condition].index\n",
    "        submission.loc[idx, f'{pum}_가격(원/kg)'] = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/xgb_update.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/sample_submission.csv')\n",
    "public_date_list = submission[submission['예측대상일자'].str.contains('2021')]['예측대상일자'].str.split('+').str[0].unique()\n",
    "# ['2021-09-28', ...]\n",
    "\n",
    "date = public_date_list[37] # 10/08기준 [10]에서 1씩 늘려가기 ex.10/09 > [11], 10월은 해당 날짜 +2\n",
    "\n",
    "test = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/data/test_update.csv')\n",
    "for pum in unique_pum + unique_kind:\n",
    "# 예측기준일에 대해 전처리\n",
    "    temp_test = pd.DataFrame([{'date' : date}]) #예측기준일\n",
    "    alldata = pd.concat([test, temp_test], sort=False).reset_index(drop=True)\n",
    "    alldata = alldata[['date', f'{pum}_거래량(kg)', f'{pum}_가격(원/kg)']].fillna(0)\n",
    "    alldata = alldata.iloc[-29:].reset_index(drop=True)\n",
    "    alldata = preprocessing(alldata, pum, len_lag=28)\n",
    "    temp_test = alldata.iloc[-1].astype(float)\n",
    "# 개별 모델을 활용하여 1,2,4주 후 가격 예측\n",
    "    for week_num in [1,2,4] :\n",
    "        temp_model = model_dict2[f'{pum}_model_{week_num}']\n",
    "        result = temp_model.predict(temp_test[:-3].values.reshape(1, -1))\n",
    "        condition = (submission['예측대상일자']==f'{date}+{week_num}week')\n",
    "        idx = submission[condition].index\n",
    "        submission.loc[idx, f'{pum}_가격(원/kg)'] = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/Ada_update.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/sample_submission.csv')\n",
    "public_date_list = submission[submission['예측대상일자'].str.contains('2021')]['예측대상일자'].str.split('+').str[0].unique()\n",
    "# ['2021-09-28', ...]\n",
    "\n",
    "date = public_date_list[37] # 10/08기준 [10]에서 1씩 늘려가기 ex.10/09 > [11], 10월은 해당 날짜 +2\n",
    "\n",
    "test = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/data/test_update.csv')\n",
    "for pum in unique_pum + unique_kind:\n",
    "# 예측기준일에 대해 전처리\n",
    "    temp_test = pd.DataFrame([{'date' : date}]) #예측기준일\n",
    "    alldata = pd.concat([test, temp_test], sort=False).reset_index(drop=True)\n",
    "    alldata = alldata[['date', f'{pum}_거래량(kg)', f'{pum}_가격(원/kg)']].fillna(0)\n",
    "    alldata = alldata.iloc[-29:].reset_index(drop=True)\n",
    "    alldata = preprocessing(alldata, pum, len_lag=28)\n",
    "    temp_test = alldata.iloc[-1].astype(float)\n",
    "# 개별 모델을 활용하여 1,2,4주 후 가격 예측\n",
    "    for week_num in [1,2,4] :\n",
    "        temp_model = model_dict3[f'{pum}_model_{week_num}']\n",
    "        result = temp_model.predict(temp_test[:-3].values.reshape(1, -1))\n",
    "        condition = (submission['예측대상일자']==f'{date}+{week_num}week')\n",
    "        idx = submission[condition].index\n",
    "        submission.loc[idx, f'{pum}_가격(원/kg)'] = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/LGBM_update.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/sample_submission.csv')\n",
    "public_date_list = submission[submission['예측대상일자'].str.contains('2021')]['예측대상일자'].str.split('+').str[0].unique()\n",
    "# ['2021-09-28', ...]\n",
    "\n",
    "date = public_date_list[37] # 10/08기준 [10]에서 1씩 늘려가기 ex.10/09 > [11], 10월은 해당 날짜 +2\n",
    "\n",
    "test = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/data/test_update.csv')\n",
    "for pum in unique_pum + unique_kind:\n",
    "# 예측기준일에 대해 전처리\n",
    "    temp_test = pd.DataFrame([{'date' : date}]) #예측기준일\n",
    "    alldata = pd.concat([test, temp_test], sort=False).reset_index(drop=True)\n",
    "    alldata = alldata[['date', f'{pum}_거래량(kg)', f'{pum}_가격(원/kg)']].fillna(0)\n",
    "    alldata = alldata.iloc[-29:].reset_index(drop=True)\n",
    "    alldata = preprocessing(alldata, pum, len_lag=28)\n",
    "    temp_test = alldata.iloc[-1].astype(float)\n",
    "# 개별 모델을 활용하여 1,2,4주 후 가격 예측\n",
    "    for week_num in [1,2,4] :\n",
    "        temp_model = model_dict4[f'{pum}_model_{week_num}']\n",
    "        result = temp_model.predict(temp_test[:-3].values.reshape(1, -1))\n",
    "        condition = (submission['예측대상일자']==f'{date}+{week_num}week')\n",
    "        idx = submission[condition].index\n",
    "        submission.loc[idx, f'{pum}_가격(원/kg)'] = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/RF_update.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight(가중치)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgb = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/xgb_update.csv')\n",
    "Ada = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/Ada_update.csv')\n",
    "Lgbm = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/LGBM_update.csv')\n",
    "Rf = pd.read_csv('C:/Users/KISLAB03/Desktop/2021-2/1234/RF_update.csv')\n",
    "\n",
    "Rf.iloc[225:228,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10/08기준 [144:147, 1:]에서 3씩 늘려가기 ex.10/09 > [147:150, 1:]\n",
    "con_all= Xgb.iloc[225:228,1:]*0.1 + Ada.iloc[225:228,1:]*0.35 + Lgbm.iloc[225:228,1:]*0.45 + Rf.iloc[225:228,1:]*0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conjun = pd.concat([Xgb['예측대상일자'],con_all],axis=1)\n",
    "conjun=conjun.fillna(0)\n",
    "\n",
    "# conjun.iloc[225:228,]\n",
    "\n",
    "conjun.to_csv(\"C:/Users/KISLAB03/Desktop/2021-2/1234/finally_update.csv\", index=False, encoding='UTF-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
